{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 1. Pandas, метод ближайших соседей и решающие деревья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Викулин Всеволод Александрович\n",
    " \n",
    "Группа:  517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответьте на вопросы о данных по авиарейсам в США за январь-апрель 2008 года.\n",
    "\n",
    "Данные: http://stat-computing.org/dataexpo/2009/2008.csv.bz2\n",
    "(обратите внимание, что распаковывать этот файл не обязательно — функция `pandas.read_csv` умеет читать из архивов автоматически)\n",
    "\n",
    "Описание: http://stat-computing.org/dataexpo/2009/the-data.html\n",
    "\n",
    "1. Какая из причин отмены рейса (`CancellationCode`) была самой частой? (расшифровки кодов можно найти в описании данных)\n",
    "2. Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом.\n",
    "3. Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?\n",
    "4. Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?\n",
    "5. Найдите для каждого аэропорта среднее время полета (`AirTime`) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?\n",
    "6. Найдите аэропорт, у которого наибольшая доля задержанных (`DepDelay > 0`) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию `filter` после `groupby`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"2008.csv.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>...</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>2225</td>\n",
       "      <td>WN</td>\n",
       "      <td>335</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>754.0</td>\n",
       "      <td>735</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>WN</td>\n",
       "      <td>3231</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>628.0</td>\n",
       "      <td>620</td>\n",
       "      <td>804.0</td>\n",
       "      <td>750</td>\n",
       "      <td>WN</td>\n",
       "      <td>448</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>926.0</td>\n",
       "      <td>930</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>1100</td>\n",
       "      <td>WN</td>\n",
       "      <td>1746</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>1755</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>1925</td>\n",
       "      <td>WN</td>\n",
       "      <td>3920</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  \\\n",
       "0  2008      1           3          4   2003.0        1955   2211.0   \n",
       "1  2008      1           3          4    754.0         735   1002.0   \n",
       "2  2008      1           3          4    628.0         620    804.0   \n",
       "3  2008      1           3          4    926.0         930   1054.0   \n",
       "4  2008      1           3          4   1829.0        1755   1959.0   \n",
       "\n",
       "   CRSArrTime UniqueCarrier  FlightNum        ...         TaxiIn  TaxiOut  \\\n",
       "0        2225            WN        335        ...            4.0      8.0   \n",
       "1        1000            WN       3231        ...            5.0     10.0   \n",
       "2         750            WN        448        ...            3.0     17.0   \n",
       "3        1100            WN       1746        ...            3.0      7.0   \n",
       "4        1925            WN       3920        ...            3.0     10.0   \n",
       "\n",
       "   Cancelled  CancellationCode  Diverted  CarrierDelay WeatherDelay NASDelay  \\\n",
       "0          0               NaN         0           NaN          NaN      NaN   \n",
       "1          0               NaN         0           NaN          NaN      NaN   \n",
       "2          0               NaN         0           NaN          NaN      NaN   \n",
       "3          0               NaN         0           NaN          NaN      NaN   \n",
       "4          0               NaN         0           2.0          0.0      0.0   \n",
       "\n",
       "   SecurityDelay  LateAircraftDelay  \n",
       "0            NaN                NaN  \n",
       "1            NaN                NaN  \n",
       "2            NaN                NaN  \n",
       "3            NaN                NaN  \n",
       "4            0.0               32.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancelled = df[df[\"Cancelled\"] != 0]\n",
    "df_cancelled.groupby(\"CancellationCode\").count()[\"Year\"].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726.387029425 11 4962\n",
      "         FlightNum  Year  Month  DayofMonth  DayOfWeek Origin Dest\n",
      "2547298       4988  2008      5          15          4    JFK  LGA\n",
      "4392215       5572  2008      8          10          7    JFK  LGA\n",
      "mean distance for first strange flight 770.208888889\n",
      "mean distance for second strange flight 384.751815981\n",
      "834    130\n",
      "903     59\n",
      "321     18\n",
      "223     11\n",
      "712      4\n",
      "414      1\n",
      "96       1\n",
      "11       1\n",
      "Name: Distance, dtype: int64\n",
      "329    507\n",
      "544    243\n",
      "134     42\n",
      "363     27\n",
      "508      4\n",
      "669      2\n",
      "11       1\n",
      "Name: Distance, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mean_d, min_d, max_d = df[\"Distance\"].mean(), df[\"Distance\"].min(), df[\"Distance\"].max()\n",
    "print mean_d, min_d, max_d\n",
    "strange_flights = df[df[\"Distance\"] == min_d]\n",
    "print strange_flights[[\"FlightNum\", \"Year\", \"Month\", \"DayofMonth\", \"DayOfWeek\", \"Origin\", \"Dest\"]]\n",
    "print \"mean distance for first strange flight \" + str(df[df[\"FlightNum\"] == strange_flights[\"FlightNum\"].\\\n",
    "                                                       iloc[0]][\"Distance\"].mean())\n",
    "print \"mean distance for second strange flight \" + str(df[df[\"FlightNum\"] == strange_flights[\"FlightNum\"].\\\n",
    "                                                        iloc[1]][\"Distance\"].mean())\n",
    "print df[df[\"FlightNum\"] == strange_flights[\"FlightNum\"].iloc[0]][\"Distance\"].value_counts()\n",
    "print df[df[\"FlightNum\"] == strange_flights[\"FlightNum\"].iloc[1]][\"Distance\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет, минимальное расстоние в 11 км не выглядит удивительным, так как если Вы посмотрите на Origin и Dest, (IATA code начального и конечного аэропортов) то в  обоих случаях это будут два аэропорта из города Нью-Йорк. Это как из Домодедово во Внуково, только ближе "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATL'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Origin\").count()[\"Year\"].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Яндекс сказал, что такой IATA code у Международного аэропорта Хартсфилд-Джексон в Атланте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SJU'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Origin\").mean()[\"AirTime\"].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спросим у Яндекса. Международный аэропорт имени Луиса Муньоса Маринааэропорт совместного базирования, расположенный в городе Каролина, в пяти километрах к юго-востоку от столицы Пуэрто-Рико, города Сан-Хуан. Является крупнейшим коммерческим аэропортом в Пуэрто-Рико. Но Пуэрто-Рико вроде на острове находится, так что дейтвительно летать всегда далеко."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DAL'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task_6 = df.groupby(\"Origin\").filter(lambda x: len(x) > 1000)\n",
    "def true_delay_percent(x):\n",
    "    return float(len(x[x[\"DepDelay\"] > 0]))/float(len(x))\n",
    "df_task_6.groupby(\"Origin\").agg(true_delay_percent)[\"Year\"].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это аэропорт города Даллас, штат Техас. Если посмотреть на значение, то более половины рейсов у него задержаны. Шшшикарно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: метрические методы и категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все дальнейшие эксперименты предлагается проводить на данных соревнования Amazon Employee Access Challenge: https://www.kaggle.com/c/amazon-employee-access-challenge\n",
    "\n",
    "В данной задаче предлагается предсказать, будет ли одобрен запрос сотрудника на получение доступа к тому или иному ресурсу. Все признаки являются категориальными.\n",
    "\n",
    "Для удобства данные можно загрузить по ссылке: https://www.dropbox.com/s/q6fbs1vvhd5kvek/amazon.csv\n",
    "\n",
    "Сразу прочитаем данные и создадим разбиение на обучение и контроль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39353</td>\n",
       "      <td>85475</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>123472</td>\n",
       "      <td>117905</td>\n",
       "      <td>117906</td>\n",
       "      <td>290919</td>\n",
       "      <td>117908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17183</td>\n",
       "      <td>1540</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>123125</td>\n",
       "      <td>118536</td>\n",
       "      <td>118536</td>\n",
       "      <td>308574</td>\n",
       "      <td>118539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>36724</td>\n",
       "      <td>14457</td>\n",
       "      <td>118219</td>\n",
       "      <td>118220</td>\n",
       "      <td>117884</td>\n",
       "      <td>117879</td>\n",
       "      <td>267952</td>\n",
       "      <td>19721</td>\n",
       "      <td>117880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36135</td>\n",
       "      <td>5396</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>119993</td>\n",
       "      <td>118321</td>\n",
       "      <td>240983</td>\n",
       "      <td>290919</td>\n",
       "      <td>118322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>42680</td>\n",
       "      <td>5905</td>\n",
       "      <td>117929</td>\n",
       "      <td>117930</td>\n",
       "      <td>119569</td>\n",
       "      <td>119323</td>\n",
       "      <td>123932</td>\n",
       "      <td>19793</td>\n",
       "      <td>119325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
       "0       1     39353   85475         117961         118300         123472   \n",
       "1       1     17183    1540         117961         118343         123125   \n",
       "2       1     36724   14457         118219         118220         117884   \n",
       "3       1     36135    5396         117961         118343         119993   \n",
       "4       1     42680    5905         117929         117930         119569   \n",
       "\n",
       "   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
       "0      117905            117906       290919     117908  \n",
       "1      118536            118536       308574     118539  \n",
       "2      117879            267952        19721     117880  \n",
       "3      118321            240983       290919     118322  \n",
       "4      119323            123932        19793     119325  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('amazon.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9421099209618847"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# доля положительных примеров\n",
    "data.ACTION.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION 2\n",
      "RESOURCE 7518\n",
      "MGR_ID 4243\n",
      "ROLE_ROLLUP_1 128\n",
      "ROLE_ROLLUP_2 177\n",
      "ROLE_DEPTNAME 449\n",
      "ROLE_TITLE 343\n",
      "ROLE_FAMILY_DESC 2358\n",
      "ROLE_FAMILY 67\n",
      "ROLE_CODE 343\n"
     ]
    }
   ],
   "source": [
    "# число значений у признаков\n",
    "for col_name in data.columns:\n",
    "    print col_name, len(data[col_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsevolod/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Реализуйте три функции расстояния на категориальных признаках, которые обсуждались на втором семинаре.\n",
    "\n",
    "Проще всего будет определить метрики как [user-defined distance](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html), после чего воспользоваться реализацией kNN из sklearn (в этом случае используйте функцию predict_proba). Можно реализовать метод k ближайших соседей и самостоятально — в этом случае учитите, что он должен возвращать оценку вероятности, то есть отношение объектов первого класса среди соседей к числу соседей).\n",
    "\n",
    "Постарайтесь уделить особое внимание эффективности кода — при реализации метрик \"в лоб\" вы можете столкнуться с очень большим временем выполнения.\n",
    "\n",
    "#### Подсчитайте для каждой из метрик качество на тестовой выборке `X_test` при числе соседей $k = 10$. Мера качества — AUC-ROC.\n",
    "\n",
    "#### Какая функция расстояния оказалась лучшей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"All this  functions need for calculation second and third metric in out task.\n",
    "Firste simple metric works without this funcs.\"\"\"\n",
    "def create_one_count(x, value_counts):\n",
    "    if x not in value_counts:\n",
    "        return 0, 0\n",
    "    new = value_counts[x]\n",
    "    return new, value_counts[value_counts <= new].sum()\n",
    "\n",
    "def create_counts(column, train_value_counts=None):\n",
    "    if train_value_counts is None:\n",
    "        value_counts = column.value_counts()\n",
    "        return np.array(map(lambda x : create_one_count(x=x, value_counts=value_counts), column)), value_counts\n",
    "    return np.array(map(lambda x : create_one_count(x=x, value_counts=train_value_counts), column))\n",
    "\n",
    "def make_train_counters(train_data):\n",
    "    second_metric_freq = []\n",
    "    final_train_counters = {}\n",
    "    all_names = list(train_data.columns.values)\n",
    "    for column in all_names:\n",
    "        temp, new_value_counts = create_counts(train_data[column])\n",
    "        train_data[str(column) + \" counts\"] = temp[:,0]\n",
    "        second_metric_freq.append(list(temp[:,1]))\n",
    "        final_train_counters[column] = new_value_counts\n",
    "        del train_data[column]\n",
    "    return train_data.values, final_train_counters, np.array(second_metric_freq).transpose()\n",
    "\n",
    "def make_test_counters(test_data, train_counters):\n",
    "    all_names = list(test_data.columns.values)\n",
    "    second_metric_freq = []\n",
    "    for column in all_names:\n",
    "        new_value_counts = train_counters[column]\n",
    "        temp = create_counts(test_data[column], new_value_counts)\n",
    "        test_data[str(column) + \" counts\"] = temp[:,0]\n",
    "        second_metric_freq.append(list(temp[:,1]))\n",
    "        del test_data[column]\n",
    "    return test_data.values, np.array(second_metric_freq).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CustomKNN():\n",
    "    \"\"\"my own simple KNN realization.\n",
    "    SKLEARN-like syntax Enjoy!\"\"\"\n",
    "    metric = None\n",
    "    n_neighbors = None\n",
    "    X_train = None\n",
    "    y_train = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Init our KNN\n",
    "        we have some parametrs in\n",
    "        fit and predict methods\"\"\"\n",
    "        \n",
    "    def fit(self, X_train, y_train, metric):\n",
    "        \"\"\"Simple fit function.\n",
    "        I like lazzy-learn.\"\"\"\n",
    "        self.metric = metric\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        if self.metric != \"first\":      \n",
    "            self.freq_train, self.counter, second_train = make_train_counters(pd.DataFrame(X_train))\n",
    "        if self.metric == \"second\":\n",
    "            self.freq_train = second_train /float(self.X_train.shape[0])\n",
    "                   \n",
    "    def predict(self, X_test, batch_size=1000, n_neighbors=10):\n",
    "        \"\"\"Let s try to realize \n",
    "        searching k nneighbors\"\"\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        all_predicts = np.ones(X_test.shape[0])\n",
    "        old_i = 0\n",
    "        if self.metric != \"first\":\n",
    "            freq_test, second_test = make_test_counters(pd.DataFrame(X_test),  self.counter)\n",
    "        else:\n",
    "            freq_test = np.zeros((X_test.shape[0],1))\n",
    "        if self.metric == \"second\":\n",
    "            freq_test = second_test/float(self.X_train.shape[0])\n",
    "        for i in range (0, len(X_test) / batch_size + 1*(len(X_test) % batch_size != 0)):\n",
    "            batch_predict = self.predict_for_one_batch(X_test[i*batch_size:(i+1)*batch_size,:],\\\n",
    "                                                    metric=self.metric,\\\n",
    "                                                    freq_test=freq_test[i*batch_size:(i+1)*batch_size,:])\n",
    "            all_predicts[old_i : old_i + len(batch_predict)] = batch_predict\n",
    "            old_i = len(batch_predict)*(i+1)\n",
    "        return all_predicts\n",
    "    \n",
    "    def predict_for_one_batch(self, batch, metric=\"first\", freq_test=None):\n",
    "        if metric == \"first\":\n",
    "            dist_matrix = (np.sum((self.X_train[:, np.newaxis] != batch[np.newaxis, :]) , axis=2))\n",
    "            \n",
    "        if metric == \"second\":\n",
    "            not_yet_d_mat = (self.X_train[:, np.newaxis] != batch[np.newaxis, :]) + \\\n",
    "                            ((self.X_train[:, np.newaxis] == batch[np.newaxis, :]) *\\\n",
    "                             (self.freq_train[:, np.newaxis] * freq_test[np.newaxis, :]))\n",
    "            dist_matrix = (np.sum(not_yet_d_mat , axis=2))\n",
    "            \n",
    "        if metric == \"third\":\n",
    "            dist_matrix = np.sum( ((self.X_train[:, np.newaxis] != batch[np.newaxis, :]) *\\\n",
    "                                   (np.log(self.freq_train[:, np.newaxis] + 1) * np.log(freq_test[np.newaxis, :] + 1)) ) , axis=2)\n",
    "        \n",
    "        dist_matrix = np.argsort(dist_matrix, axis=0)[0:self.n_neighbors].transpose()\n",
    "        return [self.y_train[i].mean() for i in dist_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0521669388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "test_knn = CustomKNN()\n",
    "test_knn.fit(X_train, y_train, metric='first')\n",
    "import time\n",
    "t0 = time.time()\n",
    "result = test_knn.predict(X_test, batch_size=1000)\n",
    "print time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я применил всю свою интеллектуальную мощь, чтобы эта штука считалась максимально быстро. С размером батча 1000, первая метрика считается на тесте всего 10 - 11 секунд. Если увеличивать размер батча - будет еще быстрее, но мне жалко оперативы. Две другие метрики работают уже не так быстро, но это не потому что  я их плохо написал, (то есть, не только поэтому) а потому что сначала нам для второй метрики надо посчитать дурацкую матрицу из сумм вероятностей. Считается она довольно долго в тех 4-х функциях, которые выше. Сами вычисления же, если  у нас будет эта матрица в руках (можно просто ее заранее посчитать, но тут такой трюк не показан, так как это костыль, но само исследование проводилось с ним, чтобы не ждать лишнюю тонну секунд), делаются не сильно дольше чем первая метрика. Я горжусь этой скоростью!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83088009598014845"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81983019449781858"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "test_knn.fit(X_train, y_train, metric='second')\n",
    "result = test_knn.predict(X_test, batch_size=1000)\n",
    "roc_auc_score(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82096677787194638"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "test_knn.fit(X_train, y_train, metric='third')\n",
    "result = test_knn.predict(X_test, batch_size=1000)\n",
    "roc_auc_score(y_test, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 (бонус). Подберите лучшее (на тестовой выборке) число соседей $k$ для каждой из функций расстояния. Какое наилучшее качество удалось получить?\n",
    "\n",
    "Для подбора можно использовать любые средства из sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь   я формил некоторую вооображемую табличку, для каждой из метрик указано качество для всех провеернных количествах соседей. Все делал тупо, перебирал в цикле все эти варианты и  для разных random state сплитов, чтобы было честнее, на самом деле АУК сильно зависит от того, как Вы поделите выборку, а затем записывал, но я старался!!!\n",
    "\n",
    "первая : 20 - 0.824, 19 - 0.824, 18-0.823, 17 - 0.826, 16 - 0.828, 15 - 0.828, 14 - 0.831, 13 - 0.831, 12-0.829, 11 -  0.831,  10 - 0.831, 9 - 0.830, 8 - 0.830, 7 - 0.829, 6 - 0.827\n",
    "\n",
    "\n",
    "вторая : 20 -0.811, 19 - 0.814, 18 -0.815, 17 - 0.819, 16 - 0.822, 15 - 0.821,v14- 0.819,13 - 0.821, 12 - 0.821, 11- 0.82, 10 - 0.82, 9 - 0.821, 8 - 0.822, 7 - 0.823, 6 - 0.817\n",
    "\n",
    "\n",
    "третья : 20- 0.807, 19 - 0.808, 18 - 0.809, 17 - 0.815, 16 -0.810, 15- 0.812,14 -0.817 ,13 - 0.818, 12 - 0.82, 11 - 0.819 , 10 - 0.821, 9 - 0.8211, 8 -  0.8197, 7 - 0.8197, 6 - 0.815"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Краткое резюме по поводу метрик. Тестирование было не очень честное, потому что я старался как-то усреднять по нескольким случайным разбиениям, оказалось, что скор сильно будет разный от этого. Возможно, я просто фигово реализовал 2 и 3 метрики, потому что чисто интуитивно мне кажется, что они должны работать лучше. Но ошибку я найти не смог, так что оставляю такие результаты, которые немножко зависят от рандома. Ну зато, хотя бы быстро :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Реализуйте счетчики (http://blogs.technet.com/b/machinelearning/archive/2015/02/17/big-learning-made-easy-with-counts.aspx), которые заменят категориальные признаки на вещественные.\n",
    "\n",
    "А именно, каждый категориальный признак нужно заменить на три: \n",
    "1. Число `counts` объектов в обучающей выборке с таким же значением признака.\n",
    "2. Число `successes` объектов первого класса ($y = 1$) в обучающей выборке с таким же значением признака.\n",
    "3. Сглаженное отношение двух предыдущих величин: (`successes` + 1) / (`counts` + 2).\n",
    "\n",
    "Поскольку признаки, содержащие информацию о целевой переменной, могут привести к переобучению, может оказаться полезным сделать *фолдинг*: разбить обучающую выборку на $n$ частей, и для $i$-й части считать `counts` и `successes` по всем остальным частям. Для тестовой выборки используются счетчики, посчитанные по всей обучающей выборке. Реализуйте и такой вариант. Можно использовать $n = 3$.\n",
    "\n",
    "#### Посчитайте на тесте AUC-ROC метода $k$ ближайших соседей с евклидовой метрикой для выборки, где категориальные признаки заменены на счетчики. Сравните по AUC-ROC два варианта формирования выборки — с фолдингом и без. Не забудьте подобрать наилучшее число соседей $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_one_count(x, value_counts):\n",
    "    if x not in value_counts:\n",
    "        return 0\n",
    "    return value_counts[x]\n",
    "\n",
    "def create_counts(column, train_value_counts=None):\n",
    "    if train_value_counts is None:\n",
    "        value_counts = column.value_counts()\n",
    "        return map(lambda x : create_one_count(x=x, value_counts=value_counts), column), value_counts\n",
    "    return map(lambda x : create_one_count(x=x, value_counts=train_value_counts), column)\n",
    "\n",
    "def make_train_counters(train_data, train_target):\n",
    "    final_train_counters = {}\n",
    "    all_names = list(train_data.columns.values)\n",
    "    for column in all_names:\n",
    "        train_data[column + \" counts\"], new_value_counts = create_counts(train_data[column])\n",
    "        success_train_data = train_data[train_target == 1]\n",
    "        temp, new_value_successes = create_counts(success_train_data[column])\n",
    "        train_data[column + \" successes\"] = create_counts(train_data[column], new_value_successes)\n",
    "        train_data[column + \" smooth\"] = (train_data[column + \" successes\"] + 1.0).values/(train_data[column + \" counts\"] + 2.0).values\n",
    "        final_train_counters[column] = (new_value_counts, new_value_successes)\n",
    "        del train_data[column]\n",
    "    return train_data, final_train_counters\n",
    "\n",
    "\n",
    "\n",
    "def make_test_counters(test_data, train_counters, num_folds=1):\n",
    "    all_names = list(test_data.columns.values)\n",
    "    alpha = 1.0\n",
    "    if num_folds != 1:\n",
    "        alpha =  float(num_folds - 1)/(float(num_folds))\n",
    "    for column in all_names:\n",
    "        new_value_counts = train_counters[column][0]\n",
    "        new_value_successes = train_counters[column][1]\n",
    "        test_data[column + \" counts\"] = create_counts(test_data[column], new_value_counts)\n",
    "        test_data[column + \" successes\"] = create_counts(test_data[column], new_value_successes)\n",
    "        test_data[column + \" counts\"] *= alpha\n",
    "        test_data[column + \" counts\"] = test_data[column + \" counts\"].round()\n",
    "        test_data[column + \" successes\"] *= alpha\n",
    "        test_data[column + \" successes\"] = test_data[column + \" successes\"].round()\n",
    "        test_data[column + \" smooth\"] = (test_data[column + \" successes\"] + 1.0).values/(test_data[column + \" counts\"] + 2.0).values\n",
    "        del test_data[column]\n",
    "    return test_data\n",
    "\n",
    "def simple_realization(X_train, y_train, X_test):\n",
    "    X_train, train_counters = make_train_counters(X_train, y_train)\n",
    "    X_test = make_test_counters(X_test, train_counters)\n",
    "    return X_train, X_test\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "def hard_realization(X_train, y_train, X_test, num_folds=5):\n",
    "    kf = KFold(num_folds)\n",
    "    new_train_data = pd.DataFrame()\n",
    "    new_train_target = pd.Series()\n",
    "    for train, test in kf.split(X_train):\n",
    "        kf_train = X_train.iloc[train].copy()\n",
    "        kf_test = X_train.iloc[test].copy()\n",
    "        kf_y_train = y_train.iloc[train]\n",
    "        kf_y_test = y_train.iloc[test]\n",
    "        kf_train, kf_train_counters = make_train_counters(kf_train, kf_y_train)\n",
    "        kf_test = make_test_counters(kf_test, kf_train_counters)\n",
    "        new_train_data = new_train_data.append(kf_test.copy())\n",
    "        new_train_target = new_train_target.append(kf_y_test)\n",
    "    all_x_train, train_counters = make_train_counters(X_train, y_train)\n",
    "    new_X_test = make_test_counters(X_test.copy(), train_counters, num_folds=num_folds)\n",
    "    new_X_train = new_train_data\n",
    "    new_y_train = new_train_target\n",
    "    return new_X_train, new_y_train, new_X_test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)\n",
    "X_train1, X_test1 =  simple_realization(X_train, y_train, X_test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)\n",
    "X_train2, y_train2, X_test2 = hard_realization(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESOURCE counts</th>\n",
       "      <th>RESOURCE successes</th>\n",
       "      <th>RESOURCE smooth</th>\n",
       "      <th>MGR_ID counts</th>\n",
       "      <th>MGR_ID successes</th>\n",
       "      <th>MGR_ID smooth</th>\n",
       "      <th>ROLE_ROLLUP_1 counts</th>\n",
       "      <th>ROLE_ROLLUP_1 successes</th>\n",
       "      <th>ROLE_ROLLUP_1 smooth</th>\n",
       "      <th>ROLE_ROLLUP_2 counts</th>\n",
       "      <th>...</th>\n",
       "      <th>ROLE_TITLE smooth</th>\n",
       "      <th>ROLE_FAMILY_DESC counts</th>\n",
       "      <th>ROLE_FAMILY_DESC successes</th>\n",
       "      <th>ROLE_FAMILY_DESC smooth</th>\n",
       "      <th>ROLE_FAMILY counts</th>\n",
       "      <th>ROLE_FAMILY successes</th>\n",
       "      <th>ROLE_FAMILY smooth</th>\n",
       "      <th>ROLE_CODE counts</th>\n",
       "      <th>ROLE_CODE successes</th>\n",
       "      <th>ROLE_CODE smooth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24312</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>11957.0</td>\n",
       "      <td>11379.0</td>\n",
       "      <td>0.951585</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940223</td>\n",
       "      <td>74.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>6132.0</td>\n",
       "      <td>5798.0</td>\n",
       "      <td>0.945386</td>\n",
       "      <td>985.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>0.940223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12246</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>11957.0</td>\n",
       "      <td>11379.0</td>\n",
       "      <td>0.951585</td>\n",
       "      <td>522.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974576</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>6132.0</td>\n",
       "      <td>5798.0</td>\n",
       "      <td>0.945386</td>\n",
       "      <td>116.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.974576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15099</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>11957.0</td>\n",
       "      <td>11379.0</td>\n",
       "      <td>0.951585</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883838</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>734.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>196.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.883838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>11957.0</td>\n",
       "      <td>11379.0</td>\n",
       "      <td>0.951585</td>\n",
       "      <td>941.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921374</td>\n",
       "      <td>3866.0</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>0.934592</td>\n",
       "      <td>6132.0</td>\n",
       "      <td>5798.0</td>\n",
       "      <td>0.945386</td>\n",
       "      <td>2618.0</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>0.921374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24776</th>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881944</td>\n",
       "      <td>311.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>0.888179</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>0.899932</td>\n",
       "      <td>718.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>0.881944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RESOURCE counts  RESOURCE successes  RESOURCE smooth  MGR_ID counts  \\\n",
       "24312              3.0                 3.0         0.800000           26.0   \n",
       "12246              4.0                 4.0         0.833333           22.0   \n",
       "15099             10.0                 9.0         0.833333           13.0   \n",
       "22149              0.0                 0.0         0.500000           26.0   \n",
       "24776             11.0                10.0         0.846154            4.0   \n",
       "\n",
       "       MGR_ID successes  MGR_ID smooth  ROLE_ROLLUP_1 counts  \\\n",
       "24312              26.0       0.964286               11957.0   \n",
       "12246              22.0       0.958333               11957.0   \n",
       "15099              13.0       0.933333               11957.0   \n",
       "22149              25.0       0.928571               11957.0   \n",
       "24776               2.0       0.500000                  34.0   \n",
       "\n",
       "       ROLE_ROLLUP_1 successes  ROLE_ROLLUP_1 smooth  ROLE_ROLLUP_2 counts  \\\n",
       "24312                  11379.0              0.951585                1398.0   \n",
       "12246                  11379.0              0.951585                 522.0   \n",
       "15099                  11379.0              0.951585                2500.0   \n",
       "22149                  11379.0              0.951585                 941.0   \n",
       "24776                     26.0              0.750000                  34.0   \n",
       "\n",
       "             ...         ROLE_TITLE smooth  ROLE_FAMILY_DESC counts  \\\n",
       "24312        ...                  0.940223                     74.0   \n",
       "12246        ...                  0.974576                     22.0   \n",
       "15099        ...                  0.883838                     50.0   \n",
       "22149        ...                  0.921374                   3866.0   \n",
       "24776        ...                  0.881944                    311.0   \n",
       "\n",
       "       ROLE_FAMILY_DESC successes  ROLE_FAMILY_DESC smooth  \\\n",
       "24312                        72.0                 0.960526   \n",
       "12246                        22.0                 0.958333   \n",
       "15099                        50.0                 0.980769   \n",
       "22149                      3614.0                 0.934592   \n",
       "24776                       277.0                 0.888179   \n",
       "\n",
       "       ROLE_FAMILY counts  ROLE_FAMILY successes  ROLE_FAMILY smooth  \\\n",
       "24312              6132.0                 5798.0            0.945386   \n",
       "12246              6132.0                 5798.0            0.945386   \n",
       "15099               734.0                  695.0            0.945652   \n",
       "22149              6132.0                 5798.0            0.945386   \n",
       "24776              1477.0                 1330.0            0.899932   \n",
       "\n",
       "       ROLE_CODE counts  ROLE_CODE successes  ROLE_CODE smooth  \n",
       "24312             985.0                927.0          0.940223  \n",
       "12246             116.0                114.0          0.974576  \n",
       "15099             196.0                174.0          0.883838  \n",
       "22149            2618.0               2413.0          0.921374  \n",
       "24776             718.0                634.0          0.881944  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESOURCE counts</th>\n",
       "      <th>RESOURCE successes</th>\n",
       "      <th>RESOURCE smooth</th>\n",
       "      <th>MGR_ID counts</th>\n",
       "      <th>MGR_ID successes</th>\n",
       "      <th>MGR_ID smooth</th>\n",
       "      <th>ROLE_ROLLUP_1 counts</th>\n",
       "      <th>ROLE_ROLLUP_1 successes</th>\n",
       "      <th>ROLE_ROLLUP_1 smooth</th>\n",
       "      <th>ROLE_ROLLUP_2 counts</th>\n",
       "      <th>...</th>\n",
       "      <th>ROLE_TITLE smooth</th>\n",
       "      <th>ROLE_FAMILY_DESC counts</th>\n",
       "      <th>ROLE_FAMILY_DESC successes</th>\n",
       "      <th>ROLE_FAMILY_DESC smooth</th>\n",
       "      <th>ROLE_FAMILY counts</th>\n",
       "      <th>ROLE_FAMILY successes</th>\n",
       "      <th>ROLE_FAMILY smooth</th>\n",
       "      <th>ROLE_CODE counts</th>\n",
       "      <th>ROLE_CODE successes</th>\n",
       "      <th>ROLE_CODE smooth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24312</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>14224.0</td>\n",
       "      <td>0.951632</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940795</td>\n",
       "      <td>92.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>7665.0</td>\n",
       "      <td>7248.0</td>\n",
       "      <td>0.945481</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>0.940795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12246</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>14224.0</td>\n",
       "      <td>0.951632</td>\n",
       "      <td>652.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972789</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>7665.0</td>\n",
       "      <td>7248.0</td>\n",
       "      <td>0.945481</td>\n",
       "      <td>145.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.972789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15099</th>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>14224.0</td>\n",
       "      <td>0.951632</td>\n",
       "      <td>3125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882591</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>917.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td>0.946681</td>\n",
       "      <td>245.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.882591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>14224.0</td>\n",
       "      <td>0.951632</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921221</td>\n",
       "      <td>4833.0</td>\n",
       "      <td>4518.0</td>\n",
       "      <td>0.934643</td>\n",
       "      <td>7665.0</td>\n",
       "      <td>7248.0</td>\n",
       "      <td>0.945481</td>\n",
       "      <td>3273.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>0.921221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24776</th>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881111</td>\n",
       "      <td>389.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>0.887468</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>1662.0</td>\n",
       "      <td>0.899892</td>\n",
       "      <td>898.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>0.881111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RESOURCE counts  RESOURCE successes  RESOURCE smooth  MGR_ID counts  \\\n",
       "24312              4.0                 4.0         0.833333           33.0   \n",
       "12246              5.0                 5.0         0.857143           27.0   \n",
       "15099             12.0                11.0         0.857143           16.0   \n",
       "22149              0.0                 0.0         0.500000           32.0   \n",
       "24776             14.0                12.0         0.812500            5.0   \n",
       "\n",
       "       MGR_ID successes  MGR_ID smooth  ROLE_ROLLUP_1 counts  \\\n",
       "24312              33.0       0.971429               14946.0   \n",
       "12246              27.0       0.965517               14946.0   \n",
       "15099              16.0       0.944444               14946.0   \n",
       "22149              31.0       0.941176               14946.0   \n",
       "24776               3.0       0.571429                  43.0   \n",
       "\n",
       "       ROLE_ROLLUP_1 successes  ROLE_ROLLUP_1 smooth  ROLE_ROLLUP_2 counts  \\\n",
       "24312                  14224.0              0.951632                1748.0   \n",
       "12246                  14224.0              0.951632                 652.0   \n",
       "15099                  14224.0              0.951632                3125.0   \n",
       "22149                  14224.0              0.951632                1176.0   \n",
       "24776                     33.0              0.755556                  43.0   \n",
       "\n",
       "             ...         ROLE_TITLE smooth  ROLE_FAMILY_DESC counts  \\\n",
       "24312        ...                  0.940795                     92.0   \n",
       "12246        ...                  0.972789                     27.0   \n",
       "15099        ...                  0.882591                     63.0   \n",
       "22149        ...                  0.921221                   4833.0   \n",
       "24776        ...                  0.881111                    389.0   \n",
       "\n",
       "       ROLE_FAMILY_DESC successes  ROLE_FAMILY_DESC smooth  \\\n",
       "24312                        90.0                 0.968085   \n",
       "12246                        27.0                 0.965517   \n",
       "15099                        63.0                 0.984615   \n",
       "22149                      4518.0                 0.934643   \n",
       "24776                       346.0                 0.887468   \n",
       "\n",
       "       ROLE_FAMILY counts  ROLE_FAMILY successes  ROLE_FAMILY smooth  \\\n",
       "24312              7665.0                 7248.0            0.945481   \n",
       "12246              7665.0                 7248.0            0.945481   \n",
       "15099               917.0                  869.0            0.946681   \n",
       "22149              7665.0                 7248.0            0.945481   \n",
       "24776              1846.0                 1662.0            0.899892   \n",
       "\n",
       "       ROLE_CODE counts  ROLE_CODE successes  ROLE_CODE smooth  \n",
       "24312            1231.0               1159.0          0.940795  \n",
       "12246             145.0                142.0          0.972789  \n",
       "15099             245.0                217.0          0.882591  \n",
       "22149            3273.0               3016.0          0.921221  \n",
       "24776             898.0                792.0          0.881111  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819666567466\n"
     ]
    }
   ],
   "source": [
    "clf =  KNeighborsClassifier(n_neighbors=40, metric='hamming', weights='distance')\n",
    "clf.fit(X_train1, y_train)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print roc_auc_score(y_test, clf.predict_proba(X_test1)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751087791788\n"
     ]
    }
   ],
   "source": [
    "clf =  KNeighborsClassifier(n_neighbors=40, metric='hamming', weights='distance')\n",
    "clf.fit(X_train2, y_train2)\n",
    "print roc_auc_score(y_test, clf.predict_proba(X_test2)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Добавьте в исходную выборку парные признаки — то есть для каждой пары $(f_i, f_j)$, $i < j$ исходных категориальных признаков добавьте новый категориальный признак $f_{ij}$, значение которого является конкатенацией значений $f_i$ и $f_j$ (желательно через какой-нибудь специальный символ во избежание коллизий). Посчитайте счетчики для этой выборки, найдите качество метода $k$ ближайших соседей с наилучшим $k$ (с фолдингом и без)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_new_columns(data):\n",
    "    new_data = data.copy()\n",
    "    all_columns = list(data.columns.values)\n",
    "    for i in range(0, len(all_columns)):\n",
    "        for j in range(i+1, len(all_columns)):\n",
    "            new_data[all_columns[i] + \"&\" + all_columns[j]] = (new_data[all_columns[i]].map(str) \\\n",
    "                                          +  \"&\" + new_data[all_columns[j]].map(str))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)\n",
    "X_train = create_new_columns(X_train)\n",
    "X_test = create_new_columns(X_test)\n",
    "X_train1, X_test1 =  simple_realization(X_train, y_train, X_test)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)\n",
    "X_train = create_new_columns(X_train)\n",
    "X_test = create_new_columns(X_test)\n",
    "X_train2, y_train2, X_test2 = hard_realization(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834672181643\n"
     ]
    }
   ],
   "source": [
    "clf =  KNeighborsClassifier(n_neighbors=40, metric='hamming', weights='distance')\n",
    "clf.fit(X_train1, y_train)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print roc_auc_score(y_test, clf.predict_proba(X_test1)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81437712823\n"
     ]
    }
   ],
   "source": [
    "clf =  KNeighborsClassifier(n_neighbors=40, metric='hamming', weights='distance')\n",
    "clf.fit(X_train2, y_train2)\n",
    "print roc_auc_score(y_test, clf.predict_proba(X_test2)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3: Решающие деревья и леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Возьмите из предыдущей части выборку с парными признаками, преобразованную с помощью счетчиков без фолдинга. Настройте решающее дерево, подобрав оптимальные значения параметров `max_depth` и `min_samples_leaf`. Какой наилучший AUC-ROC на контроле удалось получить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_train = create_new_columns(X_train)\n",
    "X_test = create_new_columns(X_test)\n",
    "X_train, X_test =  simple_realization(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687284211798\n"
     ]
    }
   ],
   "source": [
    "clf =  DecisionTreeClassifier(max_depth=11, min_samples_leaf=5)\n",
    "clf.fit(X_train, y_train)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Настройте случайный лес, подобрав такое число деревьев `n_estimators`, при котором ошибка выходит на асимптоту. Какое качество на тестовой выборке он дает?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.724581470627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=700)\n",
    "clf.fit(X_train, y_train)\n",
    "print roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Возьмите выборку с парными признаками, для которой счетчики посчитаны с фолдингом. Обучите на ней случайный лес, подобрав число деревьев. Какое качество на тестовой выборке он дает? Чем вы можете объяснить изменение результата по сравнению с предыдущим пунктом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)\n",
    "X_train = create_new_columns(X_train)\n",
    "X_test = create_new_columns(X_test)\n",
    "X_train, y_train, X_test =  hard_realization(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72083593016\n"
     ]
    }
   ],
   "source": [
    "clf =  DecisionTreeClassifier(max_depth=11, min_samples_leaf=5)\n",
    "clf.fit(X_train, y_train)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867365599398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=700)\n",
    "clf.fit(X_train, y_train)\n",
    "print roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Честно сказать, я был не сильно удивлен, что скор при валидационном построении признаков сильно лучше, чем при обычном, просто по той причине, что у нас нету дата лика. В простом варианте, у нас в признаках неявно сидит сама целевая функция. Единственное, что смущало, это то, как я подобрал параметр альфа, которым мы будем занижать счетчики для тестовой выборки. Этим я объснял более плохой скор для KNN с валидационными признаками. Но в том случае, видимо при выборе KNN и метрики хэмминга это вообще не помогает, а деревья сильно переобучаются (такие по своей природе). Кстати, на мой взгляд, в случае построении парных признаков дата лик должен даже усиливаться, так как мы строим новый признак по двум другим, которые уже заведома зависят от целевой переменной. Может быть, этим можно объснить, что при парных признаках \"сложный\" KNN подобрался к \"простому\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вы можете поделиться своими мыслями о задании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Кратко по поводу заданий. Первая часть - очень простая, но проблема в том, что групбай ест нерелаьное количество оперативы, так что если памяти < 8 гб, то на таком ноуте домашку делать нереально, датасет очень большой. Хотелось бы поменьше.\n",
    "Вторая часть довольно захватывающая, но на реализацию быстрого KNN ушло много времени, за которое я бы мог посомтреть сериал и поэтому быть более готовым к вашим КР. Реально, много времени ушло :(\n",
    "Третья часть довольно простая. С ней проблем не было, фром склерн импорт дерево и все. Но в ней правда и не было ничего захватывающего.\n",
    "Резюмируя, суммарная сложность терпимая, суммарное удовлетворение от задачи выше ожидаемого."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь вставьте смешную картинку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"risovach.ru.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ну и немножко старых добрых баянов (прошлая несмешная картинка была моей!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"machineLearning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь посоветуйте преподавателям хороший фильм или сериал."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Не сериал, но видео годное: https://www.youtube.com/watch?v=PI7SLOovO5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
